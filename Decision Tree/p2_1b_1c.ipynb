{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('p2_1c.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "x_train = X.iloc[0:90,:].values\n",
    "x_test = X.iloc[90:,:].values\n",
    "y_train = Y[0:90].values.reshape(-1,1)\n",
    "y_test = Y[90:].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, attribute=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
    "        self.attribute = attribute\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.info_gain = info_gain\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    def __init__(self, min_sample=2, max_depth=8):\n",
    "        self.root = None\n",
    "        self.min_sample = min_sample\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def build_tree(self, dataset, depth=0):        \n",
    "        X, Y = dataset[:,0:3], dataset[:,3]\n",
    "        n_rows, n_cols = np.shape(X)\n",
    "        if n_rows>=self.min_sample and depth<=self.max_depth:\n",
    "            best_split = self.get_best_split(dataset, n_rows, n_cols)\n",
    "            if best_split[\"info_gain\"]>0:\n",
    "                lefttree = self.build_tree(best_split[\"left\"], depth+1)\n",
    "                righttree = self.build_tree(best_split[\"right\"], depth+1)\n",
    "                return Node(best_split[\"attribute\"], best_split[\"threshold\"], \n",
    "                            lefttree, righttree, best_split[\"info_gain\"])\n",
    "        leaf_value = self.calculate_node(Y)\n",
    "        return Node(value=leaf_value)\n",
    "    \n",
    "    def get_best_split(self, dataset, n_rows, n_cols):\n",
    "        best_split = {}\n",
    "        info_gain = -float('inf')\n",
    "        for col in range(n_cols):\n",
    "            values = dataset[:, col]\n",
    "            _thresholds = []\n",
    "            for i in range(len(values)):\n",
    "                if i != 0:\n",
    "                    current_value = values[i]\n",
    "                    next_value = values[i - 1]\n",
    "                    split_value = (current_value + next_value) / 2\n",
    "                    _thresholds.append(split_value)\n",
    "            for threshold in _thresholds:\n",
    "                left, right = self.split(dataset, col, threshold)\n",
    "                if len(left)>0 and len(right)>0:\n",
    "                    y, left_y, right_y = dataset[:, 0:3], left[:, 0:3], right[:, 0:3]\n",
    "                    IG = self.information_gain(y, left_y, right_y)\n",
    "                    if IG>info_gain:\n",
    "                        best_split[\"attribute\"] = col\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"left\"] = left\n",
    "                        best_split[\"right\"] = right\n",
    "                        best_split[\"info_gain\"] = IG\n",
    "                        info_gain = IG \n",
    "            _thresholds = []\n",
    "        return best_split\n",
    "    \n",
    "    def split(self, dataset, col, threshold):\n",
    "        dataset_left = np.array([i for i in dataset if i[col]<=threshold])\n",
    "        dataset_right = np.array([i for i in dataset if i[col]>threshold])\n",
    "        return dataset_left, dataset_right\n",
    "    \n",
    "    def information_gain(self, data, l_child, r_child):\n",
    "        total = len(l_child) + len(r_child)\n",
    "        prob_left_child = len(l_child) / total\n",
    "        prob_right_child = len(r_child) / total\n",
    "        entropy_left_child = self.entropy(l_child)\n",
    "        entropy_right_child = self.entropy(r_child)\n",
    "        entropy_of_split_data = (prob_left_child * entropy_left_child) + (prob_right_child * entropy_right_child)\n",
    "        gain = self.entropy(data) - entropy_of_split_data\n",
    "        return gain\n",
    "    \n",
    "    def entropy(self, y):\n",
    "        labels = np.unique(y)\n",
    "        entropy = 0\n",
    "        for attribute in labels:\n",
    "            p_attribute = len(y[y == attribute]) / len(y)\n",
    "            entropy += -p_attribute * np.log2(p_attribute)\n",
    "        return entropy\n",
    "\n",
    "    def calculate_node(self, Y):\n",
    "        Y = list(Y)\n",
    "        return max(Y, key=Y.count)\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        dataset = np.concatenate((X, Y), axis=1)\n",
    "        self.root = self.build_tree(dataset)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        preditions = [self.classify(x, self.root) for x in X]\n",
    "        return preditions\n",
    "    \n",
    "    def classify(self, x, tree):\n",
    "        if tree.value!=None: return tree.value\n",
    "        values = x[tree.attribute]\n",
    "        if values<=tree.threshold:\n",
    "            return self.classify(x, tree.left)\n",
    "        else:\n",
    "            return self.classify(x, tree.right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_test, y_pred):\n",
    "    correct = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_test[i] == y_pred[i]:\n",
    "            correct += 1\n",
    "    return correct/float(len(y_test)) * 100.0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth:  1\n",
      "Accuracy:  61.111111111111114\n",
      "Depth:  2\n",
      "Accuracy:  61.111111111111114\n",
      "Depth:  3\n",
      "Accuracy:  71.11111111111111\n",
      "Depth:  4\n",
      "Accuracy:  75.55555555555556\n",
      "Depth:  5\n",
      "Accuracy:  84.44444444444444\n",
      "Depth:  6\n",
      "Accuracy:  100.0\n",
      "Depth:  7\n",
      "Accuracy:  100.0\n",
      "Depth:  8\n",
      "Accuracy:  100.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 9):\n",
    "    print('Depth: ', i)\n",
    "    classifier = DecisionTree(min_sample=2, max_depth=i)\n",
    "    classifier.fit(x_train,y_train)\n",
    "    y_pred = classifier.predict(x_train)\n",
    "    acc = accuracy(y_train, y_pred)\n",
    "    print('Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth:  1\n",
      "Accuracy:  16.666666666666664\n",
      "Depth:  2\n",
      "Accuracy:  20.0\n",
      "Depth:  3\n",
      "Accuracy:  40.0\n",
      "Depth:  4\n",
      "Accuracy:  56.666666666666664\n",
      "Depth:  5\n",
      "Accuracy:  40.0\n",
      "Depth:  6\n",
      "Accuracy:  40.0\n",
      "Depth:  7\n",
      "Accuracy:  40.0\n",
      "Depth:  8\n",
      "Accuracy:  40.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 9):\n",
    "    print('Depth: ', i)\n",
    "    classifier = DecisionTree(min_sample=2, max_depth=i)\n",
    "    classifier.fit(x_train,y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    acc = accuracy(y_test, y_pred)\n",
    "    print('Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy on the train data increases till 100% as depth increases.\n",
    "for test data the best accuracy is at depth 4, 56 % after that it starts reducing. Therefore depth 4 onwards the algorithm shows overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
